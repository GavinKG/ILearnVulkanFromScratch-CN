# 同步 synchronization



// 待完善





> Implementations have significant freedom to overlap execution of work submitted to a queue, and this is common due to deep pipelining and parallelism in Vulkan devices.

由于 Vulkan API 比起前辈 OpenGL 更加偏底层，写 Vulkan 代码的人就要担负起更多的责任，控制数据执行的同步就是其中一个。这可能是一件好事，因为人工打磨出来的同步模型可能更加能调度好 GPU 并使其饱和（saturated），从而获得性能上的提升，但如果没有搞清楚 Vulkan 中同步的概念，写出来的应用程序可就不仅仅是性能不好了，甚至有可能会出现错误。所以这章我就想仔细研究一下 Vulkan 中的同步机制。



## 解决 GPU 中的指令依赖

由于 GPU 是个无情的并行计算怪兽，因此达到 GPU 的指令们很有可能就被打散，甚至乱序执行来获得最高效能。同时之前也提到了，虽然 Vulkan 有一个看似能够打包指令的 Command Buffer，但是里面的指令到达 GPU 时也已经被完全打散。这就导致在不显式加以同步的基础上：

- 同一 Command Buffer 内，在同一个状态下，action 类型的指令可能会乱序执行。

  复习一下：Vulkan 中的指令包含三种（摘自 Vulkan doc 的 *2.2. Execution model*）：

  * action 类型：draw, dispatch, clear, copy, query/timestamp operations, begin/end subpass operations
  * set state 的类型：bind pipelines, descriptor sets, and buffers, set dynamic state, push constants, set render pass/subpass state
  * perform synchronization 的类型：set/wait events, pipeline barrier, render pass/subpass dependencies

  这就意味着那些设置状态和同步的指令将会保证根据提交顺序来执行，而基本的绘制/计算等真正干活的 action 类型将可能会乱序执行。

  这比较好理解：设置状态和同步的指令如果还被打乱执行，那么绘制顺序就被完全打乱了，依赖关系也变乱了，这当然是禁止发生的，所以其会隐式保证执行顺序；但是对于同一个 Framebuffer 的绘制操作则不应该受到影响，因为在你代码写的规范的前提下，不论以何种顺序绘制场景中的物体，光栅化都会保证物体的可见性是正确的。

- 向同一个队列提交的不同 Command Buffer，执行时指令可能会乱序执行；

  前面提到了，不能够将 Command Buffer 当作打包指令的容器，因为 GPU 这边看不到这个容器，其只能看见流淌过来的指令。据说 DX12 会保证向同一个 queue 提交的不同 Command Buffer 之间不会重叠执行，但是 Vulkan 可没有这个保证，所以当然会乱序执行喽。

- 向不同队列提交的指令更没有顺序的保证。



### Execution (Pipeline) Barrier



### Memory Barrier

// TODO: memory model



### Image Memory Barrier



### Events



### Subpass Dependencies





## 渲染同步

```
CPU <--Fences--> GPU Graphics Queue <--Semaphore--> GPU Present Queue <--SwapChain--> Monitor Vblank
```



### GPU-GPU 同步：Semaphore



### CPU-GPU 同步：Fence

> Fences can be used by the host to determine completion of execution of *queue operations*.

Fence 由 GPU 示信，用来告诉 CPU 由 `vkQueueSubmit` 和 `vkQueueBindSparse` 提交的队列任务是否执行完毕。若执行完毕，阻塞方法 `vkWaitForFences` 停止阻塞并返回，继续执行之后的任务。该阻塞方法可以等待多个 Fences，并且可以设定是否等待这些 Fences 都示信，还是其中有一个示信就可以返回。CPU 同时可以通过调用非阻塞方法 `vkGetFenceStatus` 来查询一个 Fence 的状态。

Fence 只有两种状态：signal 和 unsignal。当 GPU 队列任务完成时，跟随提交队列方法提交上来的 Fence 会从 unsignal 变成 signal。想要再次利用这个 Fence 时，需要通过调用 `vkResetFences` 将状态切换到 unsignal。

由于 GPU 示信 Fence 需要将其对应的 Queue 中的任务全部排干，会浪费很多 GPU 时间，所以 Fence 一般被用来控制一帧的渲染。



### 一套渲染同步的策略

有了以上两个概念，我们可以提出如下同步策略：

1. 渲染器必须渲染完这张图之后，呈现引擎才能去拿到（拥有）这张图。

   这里使用 Semaphore，教程中称其为 `renderFinishedSemaphore`；

2. 渲染器必须能从呈现引擎拿到（拥有）一张可供渲染的图，才能对这张图进行渲染。

   这里使用 Semaphore，教程中称其为 `imageAvailableSemaphore`。

3. 当一张图的所有渲染都执行完毕后，才能够开始让客户端发起对于这张图下一次的渲染请求。

   这里使用 Fence，教程中称其为 `inFlightFence`。

下面直接上教程的伪代码，这里只抽象出来了 Fence 和 Semaphore，以及提交和同步相关的方法：

```
VkFence inFlightFence;
VkSemaphore imageAvailableSemaphore;
VkSemaphore renderFinishedSemaphore;

void drawLoop() {
    while (true) {
        vkWaitForFences(inFlightFence); // WILL BLOCK
        uint32_t imageIndex;
        vkAcquireNextImageKHR(after retriving, signal imageAvailableSemaphore) -> imageIndex; // ASYNC
        vkResetFences(inFlightFence);
        vkQueueSubmit(wait for imageAvailableSemaphore; after execution, signal inFlightFence, renderFinishedSemaphores); // ASYNC
        vkQueuePresentKHR(wait for: renderFinishedSemaphores) // ASYNC
    }
}

void main() {
    prepare();
    drawLoop();
}
```

`vkAcquireNextImageKHR` 这个方法其实非常有趣。在 Swap Chain 一章里提到了，所有被提交到呈现引擎的图，其所有者（ownership）都会变为呈现引擎。我们需要使用这个方法从呈现引擎里要到一张图进行渲染。当我们用非阻塞的参数 (timeout = 0) 调用该方法时，只要呈现引擎中拥有（own）图的时候，该方法便会返回 `VK_SUCCESS`（不考虑不适合的情况）。当然，如果你要了太多图又没 present 但还想要的话，那么就会返回 `VK_NOT_READY`。但是返回了一个成功只代表呈现器有图，你将来可以用这张图，而并不代表这张图现在就能给你用！比如说我在使用 FIFO 配置 Swap Chain 后，一张图必须呈现在屏幕上才能再度交还给渲染器进行渲染，呈现器可能返回给你一个还没呈现的，在FIFO队列里的图的 Index，那我怎么知道什么时候能用呢？这时候就可以使用该方法同样需要传入的 semaphore了，该semaphore将在渲染指令提交时被传入，在GPU渲染之前等待。当这张图的所有者从呈现引擎转移到渲染器时，渲染器即可开始渲染这张图的内容。

上述代码仅存在一个阻塞方法 `vkWaitForFences(inFlightFence)`，而正是这个方法控制了 CPU 上整个 Draw Loop 和 GPU 的时序同步。当 CPU 本身性能足够时，从代码可知，这个阻塞，也就是能否发起下一次渲染请求取决于当前渲染器是否渲染完毕，而渲染器何时渲染完毕取决于呈现引擎何时交给我这张图（呈现引擎比渲染器慢），或者渲染器本身的负载（呈现引擎比渲染器快）。如果渲染器负载大，则 CPU 这边将会阻塞到渲染完毕；如果使用 FIFO 控制 Swap Chain 同时渲染器又足以应付其工作，则呈现引擎交出图的频率则会和表面刷新率一致，该 Draw Loop 的调用频率也就会和表面刷新率一致了，nice！当然，如果还想继续控制时序，例如虽然渲染器和呈现引擎都够快，但是我就想限制帧率（Frame Cap），则需要手动在 CPU 上加以控制（throttle），例如使用 `std::this_thread::sleep_for()`。如今，大多数 PC 游戏和大型手机游戏都能够采用三重缓冲 + CPU throttle 的限制帧率方法，在保证性能不足时的流畅程度（三重缓冲）情况下，同时又保证了整个设备的功耗（手机）和硬件占用（PC）。



### 预渲染

















